# ğŸš¦ Obstruction Detection System  

A full-stack application that detects and classifies potential **obstructions** using simulated multi-sensor data.  
This project combines **Machine Learning**, **Flask**, and a **React + TailwindCSS** frontend to deliver real-time obstruction detection for autonomous systems and safety monitoring.

---

## ğŸ§  Overview  

The system processes readings from multiple sensors (distance, LiDAR, camera, IR, sonar) and uses trained **KNN** and **Naive Bayes** models to determine whether an obstruction is present.  
It is designed to simulate an intelligent obstacle-detection pipeline suitable for self-driving vehicles, robotics, or IoT applications.

---

## ğŸš€ Features  

- ğŸ§© Multi-sensor data analysis (Distance, LiDAR, Camera, IR, Sonar)  
- ğŸ§  Machine Learning inference using **KNN** and **GaussianNB**  
- âš™ï¸ Backend built with **Flask + scikit-learn**  
- ğŸ’» Frontend built with **React + Vite + TailwindCSS**  
- ğŸ”„ Real-time predictions via REST API  
- ğŸ§° Modular structure â€” separate backend and frontend folders  

---

## ğŸ—ï¸ Tech Stack  

| Layer | Technologies |
|-------|---------------|
| **Backend** | Python, Flask, scikit-learn, NumPy, Pandas |
| **Frontend** | React, Vite, TailwindCSS, Axios |
| **ML Models** | K-Nearest Neighbors, Gaussian Naive Bayes |
| **Data Simulation** | Synthetic sensor data generator for testing |

---

## ğŸ“ Folder Structure  

```
ğŸ“ Obstruction-Detection-System/
â”‚
â”œâ”€â”€ ğŸ“‚ backend/
â”‚   â”œâ”€â”€ ğŸ“„ app.py
â”‚   â”œâ”€â”€ ğŸ“‚ routes/
â”‚   â”‚   â””â”€â”€ detection.py
â”‚   â”œâ”€â”€ ğŸ“‚ model/
â”‚   â”‚   â”œâ”€â”€ knn.pkl
â”‚   â”‚   â””â”€â”€ nb.pkl
â”‚   â”œâ”€â”€ ğŸ“‚ processed/
â”‚   â”‚   â”œâ”€â”€ scaler.pkl
â”‚   â”‚   â””â”€â”€ sample_dataset.csv
â”‚   â”œâ”€â”€ ğŸ“‚ utils/
â”‚   â”‚   â””â”€â”€ sensors.py
â”‚   â”œâ”€â”€ ğŸ“„ requirements.txt
â”‚   â””â”€â”€ ğŸ“„ README.md
â”‚
â””â”€â”€ ğŸ“‚ frontend/
    â”œâ”€â”€ ğŸ“‚ public/
    â”‚   â””â”€â”€ index.html
    â”œâ”€â”€ ğŸ“‚ src/
    â”‚   â”œâ”€â”€ App.jsx
    â”‚   â”œâ”€â”€ main.jsx
    â”‚   â”œâ”€â”€ ğŸ“‚ api/
    â”‚   â”‚   â””â”€â”€ detectionAPI.js
    â”‚   â”œâ”€â”€ ğŸ“‚ components/
    â”‚   â”‚   â”œâ”€â”€ SensorInput.jsx
    â”‚   â”‚   â””â”€â”€ ResultCard.jsx
    â”‚   â””â”€â”€ ğŸ“‚ pages/
    â”‚       â””â”€â”€ Home.jsx
    â”œâ”€â”€ ğŸ“„ package.json
    â”œâ”€â”€ ğŸ“„ tailwind.config.js
    â”œâ”€â”€ ğŸ“„ vite.config.js
    â””â”€â”€ ğŸ“„ README.md
```


---

## âš™ï¸ Setup & Run  

### ğŸ§© Backend Setup  

```bash
cd backend
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate
pip install -r requirements.txt
python app.py
```
The backend will start on http://localhost:5000

ğŸ’» Frontend Setup

```bash
cd frontend
npm install
npm run dev
```

Frontend will be available on http://localhost:5173

ğŸ”¬ How It Works
 1.Data Simulation: Synthetic sensor data is generated to simulate distance, IR temperature difference, and other readings.
 2. Model Training: The backend includes pre-trained KNN and Naive Bayes models that classify each sample as either â€œClearâ€ or â€œObstruction Detectedâ€.
 3. Prediction API: The frontend sends sensor readings to the Flask API at /api/predict.
 4. Real-Time Detection: The backend returns a prediction and confidence probability, which is displayed instantly in the web interface.

ğŸ“ˆ Example Input / Output

Input:
```json
{
  "distance_cm": 48.7,
  "lidar_intensity": 0.52,
  "camera_confidence": 0.74,
  "ir_temp_diff": 1.6,
  "sonar_echo": 0.42
}
```
Output:
```json
{
  "prediction": "OBSTRUCTION DETECTED",
  "probability": 0.87
}
```

ğŸ¯ Future Improvements
 1. Integrate real-world sensor data from Raspberry Pi or microcontrollers
 2. Add time-series models (LSTM) for temporal pattern detection
 3. Deploy backend to Render / AWS / Railway
 4. Add real-time graphs in the frontend using Chart.js or Recharts
 5. Implement a dashboard for analytics and system health monitoring.
